# app/ml/embedder.py

import requests
import os

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
MODEL_NAME = os.getenv("OLLAMA_MODEL", "llama3")  # –∏–ª–∏ bge-base, nomic-embed, —á—Ç–æ —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å

def get_embedding(text: str) -> list[float]:
    print(f"üîç –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (–¥–ª–∏–Ω–∞ {len(text)}): {text[:60]}...")
    response = requests.post(
        f"{OLLAMA_URL}/api/embeddings",
        json={"model": MODEL_NAME, "prompt": text}
    )
    response.raise_for_status()

    embedding = response.json().get("embedding")
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ –≤–ª–æ–∂–µ–Ω: [[...]] ‚Üí [...]
    if isinstance(embedding, list) and len(embedding) == 1 and isinstance(embedding[0], list):
        embedding = embedding[0]

    if not isinstance(embedding, list) or not embedding:
        raise ValueError("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π embedding")
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ list[float] –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    return [float(x) for x in embedding]
