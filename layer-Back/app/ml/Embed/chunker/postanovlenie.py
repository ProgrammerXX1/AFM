import re
import hashlib
from typing import List, Dict

SECTION_TO_TYPE = {
    "title": "title",
    "intro": "intro",
    "identity_info": "identity_info",
    "fact": "fact",
    "decision": "decision",
    "final_notice": "decision",
    "rights_notice": "rights_notice",
    "signature": "signature",
    "technical_signature": "metadata",
}

def normalize_text(text: str) -> str:
    text = text.lower()
    text = re.sub(r"mailto:[\w@.]+", "", text)
    text = re.sub(r"(qr-ÐºÐ¾Ð´.*|Ð¸Ñ Â«ÐµÐ´Ð¸Ð½Ñ‹Ð¹ Ñ€ÐµÐµÑÑ‚Ñ€.*?)", "", text)
    text = re.sub(r"\s+", " ", text)
    text = re.sub(r"[^\w\s.,:;()\[\]@-]", "", text)
    return text.strip()

def split_long_text(text: str, chunk_template: Dict, max_len: int = 1500) -> List[Dict]:
    chunks = []
    paragraphs = re.split(r"(?<=\d\))", text)
    buffer = ""
    count = 1

    for para in paragraphs:
        buffer += para
        if len(buffer) > max_len:
            new_chunk = chunk_template.copy()
            new_chunk["text"] = buffer.strip()
            new_chunk["chunk_subtype"] = f"{chunk_template['chunk_type']}_part_{count}"
            new_chunk["semantic_hash"] = hashlib.md5(normalize_text(buffer).encode()).hexdigest()
            new_chunk["hash"] = hashlib.md5(buffer.encode()).hexdigest()
            chunks.append(new_chunk)
            buffer = ""
            count += 1

    if buffer.strip():
        new_chunk = chunk_template.copy()
        new_chunk["text"] = buffer.strip()
        new_chunk["chunk_subtype"] = f"{chunk_template['chunk_type']}_part_{count}"
        new_chunk["semantic_hash"] = hashlib.md5(normalize_text(buffer).encode()).hexdigest()
        new_chunk["hash"] = hashlib.md5(buffer.encode()).hexdigest()
        chunks.append(new_chunk)

    return chunks

def chunk_postanovlenie(
    text: str,
    filetype: str,
    document_id: int,
    case_id: int,
    user_id: int
) -> List[Dict]:
    sections = {
        "title": r"(?i)^Ð¿Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ.*?$",
        "intro": r"(?i)^Ð³\.?\s?[Ð°-ÑÑ‘a-z-]{2,}(,|\s).*?$",
        "identity_info": r"(?i)^ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ\b.*?Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ².*?$",
        "fact": r"(?i)^ÑƒÑÑ‚Ð°Ð½Ð¾Ð²(?:Ð»ÐµÐ½Ð¾|Ð¸Ð»):.*?$",
        "decision": r"(?i)^Ð¿Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²(?:Ð¸Ð»|Ð»ÑÑŽ):.*?$",
        "final_notice": r"(?i)^Ð¾ Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾Ð¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¸ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð¸Ñ‚ÑŒ.*?$",
        "rights_notice": r"(?i)(Ñ€Ð°Ð·ÑŠÑÑÐ½ÐµÐ½Ñ‹.*?Ð¿Ñ€Ð°Ð²Ð°.*?|Ð¿Ñ€Ð°Ð²Ð° Ð¸ Ð¾Ð±ÑÐ·Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸.*?Ñ€Ð°Ð·ÑŠÑÑÐ½ÐµÐ½Ñ‹.*?)",
        "signature": r"(?i)^Ð¿Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾Ð±ÑŠÑÐ²Ð¸Ð».*?$|Ð¿Ð¾Ñ‚ÐµÑ€Ð¿ÐµÐ²ÑˆÐ¸Ð¹.*?Ð¿Ð¾Ð´Ð¿Ð¸ÑÑŒ|ÐºÐ¾Ð¿Ð¸ÑŽ.*?Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»|Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð»:|Ð½Ð°ÑÑ‚Ð¾ÑÑ‰.*?Ð¿Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ.*?Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¾",
        "technical_signature": r"(?i)(QR-ÐºÐ¾Ð´.*|Ð˜Ð¡ Â«ÐµÐ´Ð¸Ð½Ñ‹Ð¹ Ñ€ÐµÐµÑÑ‚Ñ€|mailto:)",
    }

    return _chunk_by_sections(text, sections, filetype, document_id, case_id, user_id)

def _chunk_by_sections(
    text: str,
    sections: Dict[str, str],
    filetype: str,
    document_id: int,
    case_id: int,
    user_id: int
) -> List[Dict]:
    pattern = re.compile("|".join(f"(?P<{key}>{regex})" for key, regex in sections.items()), re.MULTILINE)
    matches = list(pattern.finditer(text))
    chunks = []
    seen = set()

    for i, match in enumerate(matches):
        key = match.lastgroup
        start = match.start()
        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)
        chunk_text = text[start:end].strip()

        if not chunk_text or len(chunk_text) < 50:
            continue

        chunk_type = SECTION_TO_TYPE.get(key, "other")
        if chunk_type not in SECTION_TO_TYPE.values():
            chunk_type = "other"

        chunk_template = {
            "title": key.capitalize(),
            "chunk_type": chunk_type,
            "chunk_subtype": key if key in SECTION_TO_TYPE else chunk_type,
            "text": chunk_text,
            "filetype": filetype,
            "case_id": case_id,
            "document_id": document_id,
            "user_id": user_id,
            "confidence": 1.0,
            "hash": hashlib.md5(chunk_text.encode()).hexdigest(),
            "semantic_hash": hashlib.md5(normalize_text(chunk_text).encode()).hexdigest(),
            "position": -1,
            "source_page": -1,
        }

        if chunk_template["semantic_hash"] in seen:
            continue
        seen.add(chunk_template["semantic_hash"])

        if len(chunk_text) > 1500:
            chunks.extend(split_long_text(chunk_text, chunk_template))
        else:
            chunks.append(chunk_template)

    return chunks

def post_process_chunks(chunks: List[Dict]) -> List[Dict]:
    valid_types = set(SECTION_TO_TYPE.values())
    seen_semantic = set()
    result = []
    position = 1

    for chunk in chunks:
        text = chunk.get("text", "").strip()
        if not text or (len(text) < 100 and chunk.get("chunk_type") not in ("signature", "metadata")):
            continue

        sem_hash = chunk.get("semantic_hash")
        if sem_hash in seen_semantic:
            continue
        seen_semantic.add(sem_hash)

        low_text = text.lower()
        original_type = chunk.get("chunk_type")

        # ðŸ”„ Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½ÐµÐ²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð¾Ð²
        if original_type not in valid_types:
            if original_type == "signature_final":
                chunk["chunk_type"] = "signature"
                chunk["chunk_subtype"] = "signature_final"
            elif original_type == "signature_intro":
                chunk["chunk_type"] = "signature"
                chunk["chunk_subtype"] = "signature_intro"
            elif original_type == "tech_metadata":
                chunk["chunk_type"] = "metadata"
                chunk["chunk_subtype"] = "qr_signature"
            else:
                chunk["chunk_type"] = "other"

        # ðŸ§  ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ð¾Ð´Ñ‚Ð¸Ð¿Ð¾Ð²
        if "Ð¾ Ð¿Ñ€Ð¸Ð½ÑÑ‚Ð¾Ð¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ð¸ ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð¸Ñ‚ÑŒ" in low_text:
            chunk["chunk_type"] = "decision"
            chunk["chunk_subtype"] = "final_notice"
        elif "Ð¸Ð¼ÐµÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¾" in low_text:
            chunk["chunk_type"] = "rights_notice"
            chunk["chunk_subtype"] = "detailed_rights"
        elif "Ð¾Ð±ÑÐ·Ð°Ð½" in low_text:
            chunk["chunk_type"] = "rights_notice"
            chunk["chunk_subtype"] = "obligations"
        elif ("Ñ€Ð°Ð·ÑŠÑÑÐ½ÐµÐ½" in low_text or "Ñ€Ð°Ð·ÑŠÑÑÐ½ÐµÐ½Ñ‹" in low_text) and "Ð¿Ñ€Ð°Ð²Ð°" in low_text:
            chunk["chunk_type"] = "rights_notice"
            chunk["chunk_subtype"] = "confirmation"
        elif "Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð»" in low_text and "ÐºÐ¾Ð¿Ð¸ÑŽ" in low_text:
            chunk["chunk_type"] = "signature"
            chunk["chunk_subtype"] = "signature_full"
        elif "ÐºÐ¾Ð¿Ð¸ÑŽ" in low_text or "Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¾" in low_text:
            chunk["chunk_type"] = "signature"
            chunk["chunk_subtype"] = "signature_notice"
        elif chunk.get("chunk_type") == "signature":
            if not chunk.get("chunk_subtype"):
                chunk["chunk_subtype"] = "signature_author" if "Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ°Ð»" in low_text else "signature_other"
        elif chunk.get("chunk_type") == "metadata":
            chunk["chunk_subtype"] = "qr_signature"

        # âœ… Fallback subtype
        if not chunk.get("chunk_subtype") or chunk["chunk_subtype"] is None:
            chunk["chunk_subtype"] = chunk["chunk_type"]

        # ðŸš« Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        if chunk["chunk_type"] not in valid_types:
            raise ValueError(f"âŒ ÐÐµÐ´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ñ‹Ð¹ chunk_type: {chunk['chunk_type']} Ð² Ñ‡Ð°Ð½ÐºÐµ:\n{text[:200]}...")

        # âž• ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸
        chunk["position"] = position
        result.append(chunk)
        position += 1

    if not result:
        raise ValueError("âš ï¸ Ð’ÑÐµ Ñ‡Ð°Ð½ÐºÐ¸ Ð±Ñ‹Ð»Ð¸ Ð¾Ñ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ñ‹ â€” Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð¸Ð»Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚.")
    return result
