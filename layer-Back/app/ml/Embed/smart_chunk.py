from typing import List
from app.ml.Embed.chunker.base import chunk_by_filetype, get_postprocessor, detect_doc_type

def smart_chunk_document(
    text: str,
    case_id: int,
    document_id: int,
    doc_type: str = "auto",
    min_len: int = 100,
    user_id: int = 1
) -> List[dict]:
    """–ß–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ base.py —Å —É–¥–∞–ª–µ–Ω–∏–µ–º –¥—É–±–ª–µ–π –∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–æ–π."""

    # –¥–µ—Ç–µ–∫—Ç–∏–º —Ç–∏–ø
    doc_type_final = detect_doc_type(text) if doc_type == "auto" else doc_type.lower()

    # —á–∞–Ω–∫–∏—Ä—É–µ–º
    raw_chunks = chunk_by_filetype(
        text=text,
        filetype=doc_type,
        document_id=document_id,
        case_id=case_id,
        user_id=user_id
    )

    # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    seen = set()
    filtered = []
    for chunk in raw_chunks:
        norm = chunk["text"].strip()
        if len(norm) < min_len or norm in seen:
            continue
        seen.add(norm)
        chunk.setdefault("chunk_subtype", None)
        chunk.setdefault("source_page", -1)
        filtered.append(chunk)

    print(f"üì¶ –î–æ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(raw_chunks)} ‚Üí –ø–æ—Å–ª–µ: {len(filtered)}")

    # –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
    post_process = get_postprocessor(doc_type_final)
    final_chunks = post_process(filtered)
    print(f"‚úÖ –ü–æ—Å–ª–µ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(final_chunks)} —á–∞–Ω–∫–æ–≤")

    return final_chunks
