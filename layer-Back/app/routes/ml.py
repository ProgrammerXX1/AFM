from fastapi import APIRouter, Query, UploadFile, File, HTTPException, Depends
from sqlalchemy.orm import Session
from datetime import datetime, timezone
from typing import List, Optional
from pydantic import BaseModel, ConfigDict
import fitz  # PyMuPDF
import logging
import json
from app.db.database import get_db
from app.security.security import get_current_user
from app.models.cases import CaseModel, DocumentModel
from app.models.user import User
from app.core.weaviate_client import ensure_schema, client
from app.ml.Embed.pipeline import index_full_document
from app.ml.Embed.pipeline import search_similar_chunks
from app.ml.Generation.pipeline import answer_query
from app.ml.Generation.generator import generate_answer
from sqlalchemy import text
from app.ml.Embed.reranker import rerank_chunks
router = APIRouter()
logger = logging.getLogger(__name__)

# Pydantic-–º–æ–¥–µ–ª—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ GET /cases/{case_id}/documents
class DocumentResponse(BaseModel):
    id: int
    title: str
    filetype: str
    created_at: datetime
    content: str = ""

    model_config = ConfigDict(from_attributes=True)

# Pydantic-–º–æ–¥–µ–ª—å –¥–ª—è –æ—Ç–≤–µ—Ç–∞ POST /cases/{case_id}/documents
class UploadResponse(BaseModel):
    message: str

def extract_text(file: UploadFile, content: bytes) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞."""
    if file.content_type == "application/pdf":
        with fitz.open(stream=content, filetype="pdf") as doc:
            return "\n".join(page.get_text() for page in doc)
    return content.decode("utf-8", errors="ignore")

def validate_case(case_id: int, user_id: int, db: Session) -> CaseModel:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –¥–µ–ª–∞ –∏ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞."""
    case = db.query(CaseModel).filter(
        CaseModel.id == case_id,
        CaseModel.user_id == user_id
    ).first()
    if not case:
        raise HTTPException(status_code=404, detail="–î–µ–ª–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    return case

@router.get("/cases/{case_id}/documents", response_model=List[DocumentResponse])
async def get_documents(
    case_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –¥–µ–ª–∞."""
    case = validate_case(case_id, current_user.id, db)
    return case.documents

@router.post("/cases/{case_id}/documents", response_model=UploadResponse)
async def upload_documents(
    case_id: int,
    files: List[UploadFile] = File(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –¥–µ–ª–∞ —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π –≤ Weaviate."""
    case = validate_case(case_id, current_user.id, db)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    doc_count = len(case.documents) if case.documents else 0
    if doc_count + len(files) > 100:
        raise HTTPException(status_code=400, detail="–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (100)")

    processed_files = 0
    documents = []

    for file in files:
        try:
            content = await file.read()
            text = extract_text(file, content)

            # üß© –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –ë–î
            document = DocumentModel(
                title=file.filename,
                filetype=file.content_type,
                created_at=datetime.now(timezone.utc),
                case_id=case.id
            )
            db.add(document)
            db.flush()  # ‚Üê –ü–æ–ª—É—á–∞–µ–º document.id

            # ‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —á–∞–Ω–∫–æ–≤ —Å —É—á–µ—Ç–æ–º user_id –∏ doc_type="auto"
            index_full_document(
                title=file.filename,
                text=text,
                filetype=file.content_type,
                user_id=current_user.id,
                case_id=case.id,
                document_id=document.id,
                doc_type="auto"
            )

            documents.append(document)
            processed_files += 1

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file.filename}: {str(e)}")
            db.rollback()
            continue

    # ‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–º–º–∏—Ç
    try:
        db.commit()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ë–î: {str(e)}")
        db.rollback()
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î")

    return {"message": f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {processed_files} –∏–∑ {len(files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ"}


@router.get("/cases/{case_id}/search_changs")
async def semantic_search(
    case_id: int,
    q: str = Query(..., description="–í–∞—à –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"),
    current_user: User = Depends(get_current_user)
):
    try:
        logger.info(f"üîé –ó–∞–ø—Ä–æ—Å: '{q}' –¥–ª—è –¥–µ–ª–∞ #{case_id}")
        results = search_similar_chunks(query=q, case_id=case_id, k=5)
        return {"results": results}
    except Exception as e:
        logger.exception("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞")
        raise HTTPException(status_code=500, detail=str(e))

class QuestionRequest(BaseModel):
    question: str

class AnswerResponse(BaseModel):
    answer: str

def truncate_context(context: str, max_chars: int = 16000) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ –ª–∏–º–∏—Ç–∞ —Å–∏–º–≤–æ–ª–æ–≤ (–ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è LLaMA 7B –≤ Q4/Q5)."""
    if len(context) <= max_chars:
        return context
    return context[:max_chars] + "\n\n...–∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ —Ä–∞–∑–º–µ—Ä–∞..."


import re  # üëà –¥–æ–±–∞–≤—å –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω

@router.post("/ask/{case_id}")
async def ask(
    case_id: int,
    request: QuestionRequest,
    db: Session = Depends(get_db)
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (RAG: retriever + –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π reranker).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç documentSections ‚Äî —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤ (title, paragraph, ai).
    """
    try:
        logger.info(f"üì• –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è case_id={case_id}, –∑–∞–ø—Ä–æ—Å: {request.question}")

        # üîç 1. –ü–æ–ª—É—á–∞–µ–º top-k —á–∞–Ω–∫–æ–≤ (—É–∂–µ –ø–æ—Å–ª–µ rerank –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏)
        top_chunks = search_similar_chunks(query=request.question, case_id=case_id, k=10)
        chunk_texts = [chunk["text"] for chunk in top_chunks if "text" in chunk]

        if not chunk_texts:
            raise HTTPException(status_code=404, detail="–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")

        # ‚úÇÔ∏è 2. –°–±–æ—Ä–∫–∞ –∏ –æ–±—Ä–µ–∑–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = truncate_context("\n\n".join(chunk_texts))

        # üß† 3. –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        prompt = f"–í–æ–ø—Ä–æ—Å: {request.question}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n–û—Ç–≤–µ—Ç:"

        # ü§ñ 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        response_text = generate_answer(prompt)
        logger.debug("üì§ –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏:\n%s", response_text)

        # üßº 5. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON-–º–∞—Å—Å–∏–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        match = re.search(r"\[.*\]", response_text, re.DOTALL)
        if not match:
            logger.error("‚ùå –í –æ—Ç–≤–µ—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω JSON-–º–∞—Å—Å–∏–≤:\n%s", response_text)
            raise HTTPException(status_code=500, detail="–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö.")

        cleaned_json = match.group(0)

        # üì¶ 6. –ü–∞—Ä—Å–∏–Ω–≥ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON
        try:
            document_sections = json.loads(cleaned_json)
            if not isinstance(document_sections, list):
                raise ValueError("–û–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤.")

            # üí° –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
            for idx, item in enumerate(document_sections):
                if not isinstance(item, dict):
                    raise ValueError(f"–≠–ª–µ–º–µ–Ω—Ç {idx} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º.")
                if not all(k in item for k in ("title", "paragraph", "ai")):
                    raise ValueError(f"–≠–ª–µ–º–µ–Ω—Ç {idx} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª—é—á–∏ (title, paragraph, ai).")

            return document_sections

        except (json.JSONDecodeError, ValueError) as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ JSON:\n%s", cleaned_json)
            raise HTTPException(status_code=500, detail="–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON.")

    except Exception as e:
        logger.exception("üî• –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
